### Approach Explanation: Persona-Driven Document Intelligence

Our solution for the "Persona-Driven Document Intelligence" challenge is designed as a modular pipeline that intelligently filters and prioritizes information from a collection of documents, directly addressing the needs of a specific user persona. The core of our strategy is to leverage semantic understanding to bridge the gap between a user's high-level goal and the specific text contained within the documents.

Our process begins with robust document ingestion. We use the `PyPDF2` library to extract text from each PDF in the collection. Recognizing that raw text is too unstructured for meaningful analysis, we employ NLTK's sentence tokenizer to break the content down into smaller, semantically coherent chunks. This sentence-based chunking strategy is crucial, as it allows for a more granular analysis compared to paragraph or page-level chunking, ensuring that highly relevant but short passages are not lost in a sea of irrelevant text.

The heart of our solution lies in semantic search. We use the highly efficient `all-MiniLM-L6-v2` sentence-transformer model to convert both the user's query (a combination of their persona and job-to-be-done) and each document chunk into dense vector embeddings. This model was specifically chosen for its excellent balance of performance and size, making it ideal for the competition's CPU-only, memory-constrained environment. By representing text as numerical vectors, we can mathematically determine semantic relevance. We use cosine similarity to calculate the "distance" between the user's query and every chunk, allowing us to rank each piece of content by how well it matches the user's intent.

Finally, to deliver actionable insights, we process the top-ranked, most relevant chunks through a summarization pipeline powered by the `distilbart-cnn-6-6` model. This lightweight yet powerful model generates concise, abstractive summaries that serve as the "Refined Text" in the final output. This step ensures that the user receives not just a pointer to a relevant section, but a direct, easy-to-digest answer to their implicit question. This multi-stage approach, combining structured chunking, semantic ranking, and intelligent summarization, allows our system to act as a true document analyst, surfacing precisely what matters to the user who matters.